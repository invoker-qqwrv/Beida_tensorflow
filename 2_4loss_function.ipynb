{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPWP1C3PU7kDf7Cy8ILA8Bp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/invoker-qqwrv/Beida_tensorflow/blob/main/2_4loss_function.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MyTaRGw2TpzW"
      },
      "outputs": [],
      "source": [
        "# 损失函数就是预测值y与标准值y_之间的差距。\n",
        "# mse：loss_mse=tf.reduce_mean(tf.square(y,y_))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# x1和x2是影响日销量的因素。销量是y_。噪声-0.05-0.05\n",
        "# 接下来构建一层的神经网络\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "SEED=23455\n",
        "rdm=np.random.RandomState(seed=SEED)  #生成[0,1)之间的随机数\n",
        "x=rdm.rand(32,2)#生成32行两列的随机数，也就是x1和x2\n",
        "y_=[[x1+x2+(rdm.rand()/10.0-0.05)] for (x1,x2) in x]  # .rand函数生成噪声[0,1)/10=[0,0.1);[0,0.1)-0.05=[-0.05,0.05)\n",
        "x=tf.cast(x, dtype=tf.float32)\n",
        "w1=tf.Variable(tf.random.normal([2,1], stddev=1,seed=1))#随机初始化w1\n",
        "epoch=15000\n",
        "lr=0.002\n",
        "for epoch in range(epoch):\n",
        "  with tf.GradientTape() as tape:\n",
        "    y=tf.matmul(x,w1)#前向传播计算结果\n",
        "    loss_mse=tf.reduce_mean(tf.square(y_-y))#损失函数均方误差\n",
        "  grads=tape.gradient(loss_mse,w1)\n",
        "  w1.assign_sub(lr*grads)\n",
        "  if epoch%500==0:\n",
        "    print(\"After %d training steps,w1 is\"%(epoch))\n",
        "    print(w1.numpy(),\"\\n\")\n",
        "print(\"Final w1 is:\",w1.numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZLRNIpj9VUU6",
        "outputId": "88966487-0529-4d38-8312-de81bc8b9156"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "After 0 training steps,w1 is\n",
            "[[-0.6630008 ]\n",
            " [-0.41332614]] \n",
            "\n",
            "After 500 training steps,w1 is\n",
            "[[0.32583413]\n",
            " [0.6252373 ]] \n",
            "\n",
            "After 1000 training steps,w1 is\n",
            "[[0.67938864]\n",
            " [0.95564044]] \n",
            "\n",
            "After 1500 training steps,w1 is\n",
            "[[0.815626 ]\n",
            " [1.0513977]] \n",
            "\n",
            "After 2000 training steps,w1 is\n",
            "[[0.8756989]\n",
            " [1.0710448]] \n",
            "\n",
            "After 2500 training steps,w1 is\n",
            "[[0.9076067]\n",
            " [1.0673648]] \n",
            "\n",
            "After 3000 training steps,w1 is\n",
            "[[0.9279425]\n",
            " [1.0576942]] \n",
            "\n",
            "After 3500 training steps,w1 is\n",
            "[[0.94266135]\n",
            " [1.047527  ]] \n",
            "\n",
            "After 4000 training steps,w1 is\n",
            "[[0.95407534]\n",
            " [1.0384357 ]] \n",
            "\n",
            "After 4500 training steps,w1 is\n",
            "[[0.96321654]\n",
            " [1.0307256 ]] \n",
            "\n",
            "After 5000 training steps,w1 is\n",
            "[[0.9706401]\n",
            " [1.0243163]] \n",
            "\n",
            "After 5500 training steps,w1 is\n",
            "[[0.9767041]\n",
            " [1.0190308]] \n",
            "\n",
            "After 6000 training steps,w1 is\n",
            "[[0.98166996]\n",
            " [1.0146861 ]] \n",
            "\n",
            "After 6500 training steps,w1 is\n",
            "[[0.98574036]\n",
            " [1.0111187 ]] \n",
            "\n",
            "After 7000 training steps,w1 is\n",
            "[[0.98907816]\n",
            " [1.0081911 ]] \n",
            "\n",
            "After 7500 training steps,w1 is\n",
            "[[0.99181557]\n",
            " [1.0057896 ]] \n",
            "\n",
            "After 8000 training steps,w1 is\n",
            "[[0.9940609]\n",
            " [1.0038207]] \n",
            "\n",
            "After 8500 training steps,w1 is\n",
            "[[0.99590254]\n",
            " [1.0022037 ]] \n",
            "\n",
            "After 9000 training steps,w1 is\n",
            "[[0.9974131]\n",
            " [1.0008799]] \n",
            "\n",
            "After 9500 training steps,w1 is\n",
            "[[0.99865234]\n",
            " [0.999793  ]] \n",
            "\n",
            "After 10000 training steps,w1 is\n",
            "[[0.99966824]\n",
            " [0.9989008 ]] \n",
            "\n",
            "After 10500 training steps,w1 is\n",
            "[[1.0005022]\n",
            " [0.9981692]] \n",
            "\n",
            "After 11000 training steps,w1 is\n",
            "[[1.0011855 ]\n",
            " [0.99756926]] \n",
            "\n",
            "After 11500 training steps,w1 is\n",
            "[[1.001748 ]\n",
            " [0.9970778]] \n",
            "\n",
            "After 12000 training steps,w1 is\n",
            "[[1.0022026 ]\n",
            " [0.99667466]] \n",
            "\n",
            "After 12500 training steps,w1 is\n",
            "[[1.0025812]\n",
            " [0.9963444]] \n",
            "\n",
            "After 13000 training steps,w1 is\n",
            "[[1.0028903]\n",
            " [0.9960733]] \n",
            "\n",
            "After 13500 training steps,w1 is\n",
            "[[1.0031397]\n",
            " [0.9958512]] \n",
            "\n",
            "After 14000 training steps,w1 is\n",
            "[[1.0033448]\n",
            " [0.9956681]] \n",
            "\n",
            "After 14500 training steps,w1 is\n",
            "[[1.0035236]\n",
            " [0.9955191]] \n",
            "\n",
            "Final w1 is: [[1.0036514 ]\n",
            " [0.99539614]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 如果也测多了，损失的是成本，预测少了，损失的是利润\n",
        "# 如果利润不等于成本，那mes产生的loss无法实现利益最大化"
      ],
      "metadata": {
        "id": "Ilrkg_UGatK9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}